{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "GHnDE3OC6lrl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f7ba6fbd-b705-48f9-d4b4-1a10f57fdd7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!pip install datasets   # Package install\\n\\nfrom datasets import load_dataset   # Huggingface 데이터셋 패키지 import\\ndata = load_dataset(\"sepidmnorozy/Korean_sentiment\")    # 데이터 다운로드\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "##### 데이터 다운로드\n",
        "# 한 번 함\n",
        "'''\n",
        "!pip install datasets   # Package install\n",
        "\n",
        "from datasets import load_dataset   # Huggingface 데이터셋 패키지 import\n",
        "data = load_dataset(\"sepidmnorozy/Korean_sentiment\")    # 데이터 다운로드\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한 번 수행함\n",
        "'''\n",
        "# connect google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Download konlpy\n",
        "%cd ./drive/MyDrive/Colab\\ Notebooks/\n",
        "! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd ./Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab_light_220429.sh\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "6G5nsz6O1ssk",
        "outputId": "c1de68b3-f846-4c52-ca2d-85f1d4fc7309"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# connect google drive\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n# Download konlpy\\n%cd ./drive/MyDrive/Colab\\\\ Notebooks/\\n! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\\n%cd ./Mecab-ko-for-Google-Colab\\n!bash install_mecab-ko_on_colab_light_220429.sh\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()\n",
        "\n",
        "sen = \"실용자연어처리 실습 진행중입니다.\"\n",
        "print(mecab.morphs(sen))\n",
        "print(mecab.nouns(sen))\n",
        "print(mecab.pos(sen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFp0OmnZa7yo",
        "outputId": "cbdaa72b-d554-4ff1-c697-6bf811c938dc"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['실용', '자연어', '처리', '실습', '진행', '중', '입니다', '.']\n",
            "['실용', '자연어', '처리', '실습', '진행', '중']\n",
            "[('실용', 'NNG'), ('자연어', 'NNG'), ('처리', 'NNG'), ('실습', 'NNG'), ('진행', 'NNG'), ('중', 'NNB'), ('입니다', 'VCP+EF'), ('.', 'SF')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 데이터 구조 훑어보기\n",
        "# print(\"Data type: \", type(data))    # 데이터 타입 확인\n",
        "# print(\"Data structure: \", data)     # 데이터 구조 확인\n",
        "# print(\"Data keys: \", data.keys())   # 데이터 키 확인\n",
        "\n",
        "print(data['train'][0])   # 실제 데이터 확인"
      ],
      "metadata": {
        "id": "8_NM2aMmCjkA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22f673c-7a74-4d09-f487-3738de6707e1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 1, 'text': '역시 명작 어렸을때 봤을때도 재밌었고 지금 봐도 몇억배 이상으로 재밌어요'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 테스트 세트 만들기\n",
        "train_data = data['train']\n",
        "dev_data = data['validation']\n",
        "test_data = data['test']\n",
        "\n",
        "print(train_data)\n",
        "print(dev_data)\n",
        "print(test_data)\n",
        "\n",
        "#train_data = train_data.map(lambda example:{\"label\": example[\"label\"], \"text\": \" \".join(mecab.morphs(example[\"text\"]))})\n",
        "#dev_data = dev_data.map(lambda example:{\"label\": example[\"label\"], \"text\": \" \".join(mecab.morphs(example[\"text\"]))})\n",
        "#test_data = test_data.map(lambda example:{\"label\": example[\"label\"], \"text\": \" \".join(mecab.morphs(example[\"text\"]))})\n",
        "\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "id": "IqbCh4yMCiEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc02f64-5b2c-4527-f0df-29951f8968d1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['label', 'text'],\n",
            "    num_rows: 36000\n",
            "})\n",
            "Dataset({\n",
            "    features: ['label', 'text'],\n",
            "    num_rows: 1333\n",
            "})\n",
            "Dataset({\n",
            "    features: ['label', 'text'],\n",
            "    num_rows: 2667\n",
            "})\n",
            "{'label': 1, 'text': '역시 명작 어렸을때 봤을때도 재밌었고 지금 봐도 몇억배 이상으로 재밌어요'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 텍스트 데이터 특성\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.hist(data['train']['label'], color='red')\n",
        "# plt.show()\n",
        "# plt.hist(data['validation']['label'], color='blue')\n",
        "# plt.show()\n",
        "# plt.hist(data['test']['label'], color='green')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "NSi7J4fvCfRd"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 텍스트와 범주형 특성 다루기 (Bag-of-words 방식으로 벡터화 하는 법 구현)\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer       # CountVectorizer: Bag of words 벡터화 구현을 하기 위한 클래스\n",
        "\n",
        "vectorizer = TfidfVectorizer(strip_accents=\"unicode\", token_pattern = r\"(?u)\\b\\w\\w+\\b|'\\w+\",ngram_range = (1,3))      # 데이터를 벡터화 해주는 모델 \n",
        "vectorizer.fit(train_data['text'])  # 텍스트 문서 모음을 토큰 수의 행렬로 변환\n",
        "\n",
        "print(vectorizer.vocabulary_)       # 텍스트 문서에 나타난 어휘의 집합을 출력\n",
        "print(len(vectorizer.vocabulary_))  # 텍스트 문서에 나타난 어휘 집합의 길이를 출력\n",
        "\n",
        "train_vectors = vectorizer.transform(train_data['text'])    # 학습 데이터를 숫자로 변환\n",
        "dev_vectors = vectorizer.transform(dev_data['text'])        # 검증 데이터를 숫자로 변환\n",
        "test_vectors = vectorizer.transform(test_data['text'])      # 테스트 데이터를 숫자로 변환\n",
        "\n",
        "# print(train_vectors)      # transform 된 결과 확인\n",
        "\n",
        "\n",
        "##### 텍스트와 범주형 특성 다루기 (Bag-of-words 방식으로 벡터화 한 것 확인하는 방법 구현)\n",
        "sample_num = -1                            # 확인하고 싶은 샘플 번호\n",
        "sample_origin = train_data[sample_num]    # 확인하고 싶은 샘플의 원래 문장\n",
        "sample_transform = train_vectors[sample_num]    # 확인하고 싶은 샘플의 transform된 결과\n",
        "sample_inverse_transform = vectorizer.inverse_transform(sample_transform) # 확인하고 싶은 샘플의 transform된 결과를 다시 단어의 조합으로 바꾼 결과\n",
        "print(\"Original Input:{}\\nTransformed: {}\\nInv-transformed: {}\".format(sample_origin, sample_transform, sample_inverse_transform))    # 출력"
      ],
      "metadata": {
        "id": "uVsAWEB2Cd2n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0e4849a-312b-4a6e-e902-59a537ea8ac7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Input:{'label': 0, 'text': \"큰 의미없이 연결'만' 되는 살인들.\"}\n",
            "Transformed:   (0, 487054)\t0.27243075545231155\n",
            "  (0, 487053)\t0.27243075545231155\n",
            "  (0, 486948)\t0.1796799673274826\n",
            "  (0, 368706)\t0.27243075545231155\n",
            "  (0, 368705)\t0.27243075545231155\n",
            "  (0, 368702)\t0.2549430815591727\n",
            "  (0, 322146)\t0.27243075545231155\n",
            "  (0, 322145)\t0.27243075545231155\n",
            "  (0, 322144)\t0.2549430815591727\n",
            "  (0, 237162)\t0.27243075545231155\n",
            "  (0, 131150)\t0.27243075545231155\n",
            "  (0, 131082)\t0.1747627525342909\n",
            "  (0, 381)\t0.27243075545231155\n",
            "  (0, 380)\t0.27243075545231155\n",
            "  (0, 379)\t0.2549430815591727\n",
            "Inv-transformed: [array(['큰 의미없이 연결', '큰 의미없이', '큰',\n",
            "       \"의미없이 연결 '만\", '의미없이 연결', '의미없이',\n",
            "       \"연결 '만 되는\", \"연결 '만\", '연결', '살인들',\n",
            "       '되는 살인들', '되는', \"'만 되는 살인들\", \"'만 되는\",\n",
            "       \"'만\"], dtype='<U338')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 훈련세트에서 훈련하고 평가하기\n",
        "from sklearn.svm import LinearSVC     #Linear kernel SVM을 사용하기 위한 클래스     \n",
        "\n",
        "svm = LinearSVC(random_state = False)     # 모델 정의\n",
        "svm.fit(train_vectors, train_data['label'])     # 모델 학습\n",
        "\n",
        "print(svm.coef_)      # weights (w)\n",
        "print(svm.intercept_)     # bias (b)"
      ],
      "metadata": {
        "id": "u_hMc3yACbYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da259a73-4705-4e17-885e-b258a3b1b9fd"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.16483908 -0.13578088 -0.13578088 ... -0.03742624 -0.03742624\n",
            "  -0.03742624]]\n",
            "[-0.06535772]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 교차 검증을 사용한 평가\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "all_data = train_data['text']+dev_data['text']+test_data['text']      # all_data = train_data + dev_data + test_data\n",
        "all_label = train_data['label']+dev_data['label']+test_data['label']  # all_label은 train_data, dev_data, test_date의 레이블을 모두 합한 것 \n",
        "all_vectors = vectorizer.transform(all_data)    # all_data를 숫자로 변환\n",
        "scores = cross_val_score(svm, all_vectors, all_label, cv=5)  # 5-cross validation\n",
        "\n",
        "print(\"All scores:\", scores)  # 전체 점수 출력\n",
        "print(\"Average: {:.2f}%\".format(scores.mean()*100)) # 다섯 번의 스코어 평균 출력\n",
        "print(\"Standard deviation: {:.6f}\".format(scores.std()))  # 표준편차 출력\n",
        " "
      ],
      "metadata": {
        "id": "Np-m5f9DCT1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "357884be-bd33-495a-a2a6-7259fc8f4ab8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All scores: [0.781125 0.7885   0.788125 0.786625 0.800875]\n",
            "Average: 78.90%\n",
            "Standard deviation: 0.006476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 그리드 탐색\n",
        "# from sklearn.model_selection import GridSearchCV    \n",
        "\n",
        "# param_grid = [{'max_iter':[500, 1000, 5000], 'C': [1, 10, 100]}]        # 학습 max_iter와 C를 변동 하이퍼파라미터로 설정\n",
        "# grid_search = GridSearchCV(svm, param_grid, cv=3)     # 하이퍼파라미터 서치 할 모델 설정, 각 모델별로 5-cross validation 실행\n",
        "# grid_search.fit(train_vectors, train_data['label'])   # transformed train data로 학습\n",
        "\n",
        "# print(grid_search.cv_results_['mean_test_score'])     # 파라미터 서치 결과\n",
        "# print(grid_search.best_params_)   #최고의 모델 파라미터 \n",
        "\n",
        "# #파라미터 서치 결과 출력\n",
        "# for mean_score, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n",
        "#   print(mean_score, params)       "
      ],
      "metadata": {
        "id": "DtH3CLrnCUhy"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 테스트 세트로 시스템 평가하기\n",
        "from sklearn.metrics import accuracy_score    # Accuracy 측정 함수 import\n",
        "\n",
        "final_model = svm #grid_search.best_estimator_     # grid search에 의해 정해진 제일 좋은 하이퍼파라미터\n",
        "\n",
        "pred_results = final_model.predict(test_vectors)    # 최종 모델로 test 데이터 예측\n",
        "accuracy = accuracy_score(test_data['label'], pred_results)   # 정확도 측정\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))   # 정확도 출력 "
      ],
      "metadata": {
        "id": "caRvzXUtCUrv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "208dbc81-73e7-43a1-bb4a-768db1e218d9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 81.85%\n"
          ]
        }
      ]
    }
  ]
}