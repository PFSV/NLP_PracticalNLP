{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "GHnDE3OC6lrl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1c4248be-1349-4f3a-bb39-07774df0a845"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!pip install datasets   # Package install\\n\\nfrom datasets import load_dataset   # Huggingface 데이터셋 패키지 import\\ndata = load_dataset(\"sepidmnorozy/Korean_sentiment\")    # 데이터 다운로드\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "##### 데이터 다운로드\n",
        "# 한 번 함\n",
        "'''\n",
        "!pip install datasets   # Package install\n",
        "\n",
        "from datasets import load_dataset   # Huggingface 데이터셋 패키지 import\n",
        "data = load_dataset(\"sepidmnorozy/Korean_sentiment\")    # 데이터 다운로드\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한 번 수행함\n",
        "'''\n",
        "# connect google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Download konlpy\n",
        "%cd ./drive/MyDrive/Colab\\ Notebooks/\n",
        "! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd ./Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab_light_220429.sh\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "6G5nsz6O1ssk",
        "outputId": "35aca071-6ef2-4778-bba6-714bfcca3f14"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# connect google drive\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n# Download konlpy\\n%cd ./drive/MyDrive/Colab\\\\ Notebooks/\\n! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\\n%cd ./Mecab-ko-for-Google-Colab\\n!bash install_mecab-ko_on_colab_light_220429.sh\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()\n",
        "\n",
        "sen = \"실용자연어처리 실습 진행중입니다.\"\n",
        "print(mecab.morphs(sen))\n",
        "print(mecab.nouns(sen))\n",
        "print(mecab.pos(sen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFp0OmnZa7yo",
        "outputId": "b74df267-8bd1-420c-9bff-8f7ed07bed00"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['실용', '자연어', '처리', '실습', '진행', '중', '입니다', '.']\n",
            "['실용', '자연어', '처리', '실습', '진행', '중']\n",
            "[('실용', 'NNG'), ('자연어', 'NNG'), ('처리', 'NNG'), ('실습', 'NNG'), ('진행', 'NNG'), ('중', 'NNB'), ('입니다', 'VCP+EF'), ('.', 'SF')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 데이터 구조 훑어보기\n",
        "# print(\"Data type: \", type(data))    # 데이터 타입 확인\n",
        "# print(\"Data structure: \", data)     # 데이터 구조 확인\n",
        "# print(\"Data keys: \", data.keys())   # 데이터 키 확인\n",
        "\n",
        "print(data['train'][0])   # 실제 데이터 확인"
      ],
      "metadata": {
        "id": "8_NM2aMmCjkA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105cf1ff-3ae3-4172-aafd-55bf5d87eb48"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 1, 'text': '역시 명작 어렸을때 봤을때도 재밌었고 지금 봐도 몇억배 이상으로 재밌어요'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 테스트 세트 만들기\n",
        "train_data = data['train']\n",
        "dev_data = data['validation']\n",
        "test_data = data['test']\n",
        "\n",
        "print(train_data)\n",
        "print(dev_data)\n",
        "print(test_data)\n",
        "\n",
        "train_data = train_data.map(lambda example:{\"label\": example[\"label\"], \"text\": \" \".join(mecab.morphs(example[\"text\"]))})\n",
        "dev_data = dev_data.map(lambda example:{\"label\": example[\"label\"], \"text\": \" \".join(mecab.morphs(example[\"text\"]))})\n",
        "test_data = test_data.map(lambda example:{\"label\": example[\"label\"], \"text\": \" \".join(mecab.morphs(example[\"text\"]))})\n",
        "\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "id": "IqbCh4yMCiEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beb29e2b-4c51-48f4-b52b-ef44343c0184"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/sepidmnorozy___csv/sepidmnorozy--Korean_sentiment-c4fbcaaf8f2ffcfa/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-5a791b0b00b6cf20.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/sepidmnorozy___csv/sepidmnorozy--Korean_sentiment-c4fbcaaf8f2ffcfa/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-e0741f5465b95d00.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/sepidmnorozy___csv/sepidmnorozy--Korean_sentiment-c4fbcaaf8f2ffcfa/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-264d57f600a89812.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['label', 'text'],\n",
            "    num_rows: 36000\n",
            "})\n",
            "Dataset({\n",
            "    features: ['label', 'text'],\n",
            "    num_rows: 1333\n",
            "})\n",
            "Dataset({\n",
            "    features: ['label', 'text'],\n",
            "    num_rows: 2667\n",
            "})\n",
            "{'label': 1, 'text': '역시 명작 어렸 을 때 봤 을 때 도 재밌 었 고 지금 봐도 몇 억 배 이상 으로 재밌 어요'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 텍스트 데이터 특성\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.hist(data['train']['label'], color='red')\n",
        "# plt.show()\n",
        "# plt.hist(data['validation']['label'], color='blue')\n",
        "# plt.show()\n",
        "# plt.hist(data['test']['label'], color='green')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "NSi7J4fvCfRd"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 텍스트와 범주형 특성 다루기 (Bag-of-words 방식으로 벡터화 하는 법 구현)\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer       # CountVectorizer: Bag of words 벡터화 구현을 하기 위한 클래스\n",
        "\n",
        "vectorizer = TfidfVectorizer(strip_accents=\"unicode\", token_pattern = r\"(?u)\\b\\w\\w+\\b|'\\w+\",ngram_range = (1,2))      # 데이터를 벡터화 해주는 모델 \n",
        "vectorizer.fit(train_data['text'])  # 텍스트 문서 모음을 토큰 수의 행렬로 변환\n",
        "\n",
        "print(vectorizer.vocabulary_)       # 텍스트 문서에 나타난 어휘의 집합을 출력\n",
        "print(len(vectorizer.vocabulary_))  # 텍스트 문서에 나타난 어휘 집합의 길이를 출력\n",
        "\n",
        "train_vectors = vectorizer.transform(train_data['text'])    # 학습 데이터를 숫자로 변환\n",
        "dev_vectors = vectorizer.transform(dev_data['text'])        # 검증 데이터를 숫자로 변환\n",
        "test_vectors = vectorizer.transform(test_data['text'])      # 테스트 데이터를 숫자로 변환\n",
        "\n",
        "# print(train_vectors)      # transform 된 결과 확인\n",
        "\n",
        "\n",
        "##### 텍스트와 범주형 특성 다루기 (Bag-of-words 방식으로 벡터화 한 것 확인하는 방법 구현)\n",
        "sample_num = -1                            # 확인하고 싶은 샘플 번호\n",
        "sample_origin = train_data[sample_num]    # 확인하고 싶은 샘플의 원래 문장\n",
        "sample_transform = train_vectors[sample_num]    # 확인하고 싶은 샘플의 transform된 결과\n",
        "sample_inverse_transform = vectorizer.inverse_transform(sample_transform) # 확인하고 싶은 샘플의 transform된 결과를 다시 단어의 조합으로 바꾼 결과\n",
        "print(\"Original Input:{}\\nTransformed: {}\\nInv-transformed: {}\".format(sample_origin, sample_transform, sample_inverse_transform))    # 출력"
      ],
      "metadata": {
        "id": "uVsAWEB2Cd2n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28600632-748e-4a37-c1ea-f2567a47979a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Input:{'label': 0, 'text': \"큰 의미 없이 연결 ' 만 ' 되 는 살인 들 .\"}\n",
            "Transformed:   (0, 203471)\t0.3094354542114961\n",
            "  (0, 203417)\t0.20712451996101208\n",
            "  (0, 162708)\t0.3094354542114961\n",
            "  (0, 162691)\t0.19666660829166394\n",
            "  (0, 140038)\t0.3306610010321105\n",
            "  (0, 140033)\t0.2498478108712802\n",
            "  (0, 133337)\t0.3306610010321105\n",
            "  (0, 133216)\t0.1743997187719626\n",
            "  (0, 106512)\t0.3306610010321105\n",
            "  (0, 106500)\t0.23398736211217852\n",
            "  (0, 79732)\t0.28820990739088176\n",
            "  (0, 79531)\t0.11015822978377737\n",
            "  (0, 66178)\t0.09557080561241525\n",
            "  (0, 63733)\t0.1604998613699301\n",
            "  (0, 63698)\t0.1253209800929586\n",
            "  (0, 45667)\t0.31824485208474995\n",
            "  (0, 44295)\t0.06513681141714016\n",
            "Inv-transformed: [array(['큰 의미', '큰', '의미 없이', '의미', '연결 만', '연결',\n",
            "       '없이 연결', '없이', '살인 들', '살인', '만 되', '만',\n",
            "       '들', '되 는', '되', '는 살인', '는'], dtype='<U69')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 훈련세트에서 훈련하고 평가하기\n",
        "from sklearn.svm import LinearSVC     #Linear kernel SVM을 사용하기 위한 클래스     \n",
        "\n",
        "svm = LinearSVC(random_state = False)     # 모델 정의\n",
        "svm.fit(train_vectors, train_data['label'])     # 모델 학습\n",
        "\n",
        "print(svm.coef_)      # weights (w)\n",
        "print(svm.intercept_)     # bias (b)"
      ],
      "metadata": {
        "id": "u_hMc3yACbYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2937fff9-0e11-48fb-b95b-b6aeeffb1d76"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.19180475 -0.19180475  0.         ...  0.15471785 -0.00546948\n",
            "  -0.00546948]]\n",
            "[-0.13440725]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 교차 검증을 사용한 평가\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "all_data = train_data['text']+dev_data['text']+test_data['text']      # all_data = train_data + dev_data + test_data\n",
        "all_label = train_data['label']+dev_data['label']+test_data['label']  # all_label은 train_data, dev_data, test_date의 레이블을 모두 합한 것 \n",
        "all_vectors = vectorizer.transform(all_data)    # all_data를 숫자로 변환\n",
        "scores = cross_val_score(svm, all_vectors, all_label, cv=5)  # 5-cross validation\n",
        "\n",
        "print(\"All scores:\", scores)  # 전체 점수 출력\n",
        "print(\"Average: {:.2f}%\".format(scores.mean()*100)) # 다섯 번의 스코어 평균 출력\n",
        "print(\"Standard deviation: {:.6f}\".format(scores.std()))  # 표준편차 출력\n",
        " "
      ],
      "metadata": {
        "id": "Np-m5f9DCT1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a9c629-1567-4512-c980-5213f1dbff21"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All scores: [0.8445   0.84925  0.847625 0.843    0.854   ]\n",
            "Average: 84.77%\n",
            "Standard deviation: 0.003858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 그리드 탐색\n",
        "# from sklearn.model_selection import GridSearchCV    \n",
        "\n",
        "# param_grid = [{'max_iter':[500, 1000, 5000], 'C': [1, 10, 100]}]        # 학습 max_iter와 C를 변동 하이퍼파라미터로 설정\n",
        "# grid_search = GridSearchCV(svm, param_grid, cv=3)     # 하이퍼파라미터 서치 할 모델 설정, 각 모델별로 5-cross validation 실행\n",
        "# grid_search.fit(train_vectors, train_data['label'])   # transformed train data로 학습\n",
        "\n",
        "# print(grid_search.cv_results_['mean_test_score'])     # 파라미터 서치 결과\n",
        "# print(grid_search.best_params_)   #최고의 모델 파라미터 \n",
        "\n",
        "# #파라미터 서치 결과 출력\n",
        "# for mean_score, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n",
        "#   print(mean_score, params)       "
      ],
      "metadata": {
        "id": "DtH3CLrnCUhy"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 테스트 세트로 시스템 평가하기\n",
        "from sklearn.metrics import accuracy_score    # Accuracy 측정 함수 import\n",
        "\n",
        "final_model = svm #grid_search.best_estimator_     # grid search에 의해 정해진 제일 좋은 하이퍼파라미터\n",
        "\n",
        "pred_results = final_model.predict(test_vectors)    # 최종 모델로 test 데이터 예측\n",
        "accuracy = accuracy_score(test_data['label'], pred_results)   # 정확도 측정\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))   # 정확도 출력 "
      ],
      "metadata": {
        "id": "caRvzXUtCUrv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a30f4035-e50e-4699-e2ed-43739e0f0a83"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 85.98%\n"
          ]
        }
      ]
    }
  ]
}