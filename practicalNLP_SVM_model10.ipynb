{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "GHnDE3OC6lrl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7b9a2899-2278-4a57-ddd7-04ad4a3d1dc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!pip install datasets   # Package install\\n\\nfrom datasets import load_dataset   # Huggingface 데이터셋 패키지 import\\ndata = load_dataset(\"sepidmnorozy/Korean_sentiment\")    # 데이터 다운로드\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "##### 데이터 다운로드\n",
        "# 한 번 함\n",
        "'''\n",
        "!pip install datasets   # Package install\n",
        "\n",
        "from datasets import load_dataset   # Huggingface 데이터셋 패키지 import\n",
        "data = load_dataset(\"sepidmnorozy/Korean_sentiment\")    # 데이터 다운로드\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한 번 수행함\n",
        "'''\n",
        "# connect google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Download konlpy\n",
        "%cd ./drive/MyDrive/Colab\\ Notebooks/\n",
        "! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd ./Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab_light_220429.sh\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "6G5nsz6O1ssk",
        "outputId": "57e04213-8869-4c64-cdf4-89cd328c6270"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# connect google drive\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n# Download konlpy\\n%cd ./drive/MyDrive/Colab\\\\ Notebooks/\\n! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\\n%cd ./Mecab-ko-for-Google-Colab\\n!bash install_mecab-ko_on_colab_light_220429.sh\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()\n",
        "\n",
        "sen = \"실용자연어처리 실습 진행중입니다.\"\n",
        "print(mecab.morphs(sen))\n",
        "print(mecab.nouns(sen))\n",
        "print(mecab.pos(sen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFp0OmnZa7yo",
        "outputId": "005c5b42-1e95-427d-a5c8-ad17527ec687"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['실용', '자연어', '처리', '실습', '진행', '중', '입니다', '.']\n",
            "['실용', '자연어', '처리', '실습', '진행', '중']\n",
            "[('실용', 'NNG'), ('자연어', 'NNG'), ('처리', 'NNG'), ('실습', 'NNG'), ('진행', 'NNG'), ('중', 'NNB'), ('입니다', 'VCP+EF'), ('.', 'SF')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 데이터 구조 훑어보기\n",
        "# print(\"Data type: \", type(data))    # 데이터 타입 확인\n",
        "# print(\"Data structure: \", data)     # 데이터 구조 확인\n",
        "# print(\"Data keys: \", data.keys())   # 데이터 키 확인\n",
        "\n",
        "print(data['train'][0])   # 실제 데이터 확인"
      ],
      "metadata": {
        "id": "8_NM2aMmCjkA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dc0a6aa-02db-44cf-e8c8-0a5cb651fc4e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 1, 'text': '역시 명작 어렸을때 봤을때도 재밌었고 지금 봐도 몇억배 이상으로 재밌어요'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 테스트 세트 만들기\n",
        "train_data = data['train']\n",
        "dev_data = data['validation']\n",
        "test_data = data['test']\n",
        "\n",
        "print(train_data)\n",
        "print(dev_data)\n",
        "print(test_data)\n",
        "\n",
        "#train_data = train_data.map(lambda example:{\"label\": example[\"label\"], \"text\": \" \".join(mecab.morphs(example[\"text\"]))})\n",
        "#dev_data = dev_data.map(lambda example:{\"label\": example[\"label\"], \"text\": \" \".join(mecab.morphs(example[\"text\"]))})\n",
        "#test_data = test_data.map(lambda example:{\"label\": example[\"label\"], \"text\": \" \".join(mecab.morphs(example[\"text\"]))})\n",
        "\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "id": "IqbCh4yMCiEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe62799-ca40-4a4a-ac13-2a0770778bbf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['label', 'text'],\n",
            "    num_rows: 36000\n",
            "})\n",
            "Dataset({\n",
            "    features: ['label', 'text'],\n",
            "    num_rows: 1333\n",
            "})\n",
            "Dataset({\n",
            "    features: ['label', 'text'],\n",
            "    num_rows: 2667\n",
            "})\n",
            "{'label': 1, 'text': '역시 명작 어렸을때 봤을때도 재밌었고 지금 봐도 몇억배 이상으로 재밌어요'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 텍스트 데이터 특성\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.hist(data['train']['label'], color='red')\n",
        "# plt.show()\n",
        "# plt.hist(data['validation']['label'], color='blue')\n",
        "# plt.show()\n",
        "# plt.hist(data['test']['label'], color='green')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "NSi7J4fvCfRd"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 텍스트와 범주형 특성 다루기 (Bag-of-words 방식으로 벡터화 하는 법 구현)\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer       # CountVectorizer: Bag of words 벡터화 구현을 하기 위한 클래스\n",
        "\n",
        "vectorizer = TfidfVectorizer(strip_accents=\"unicode\", token_pattern = r\"(?u)\\b\\w\\w+\\b|'\\w+\",ngram_range = (1,1))      # 데이터를 벡터화 해주는 모델 \n",
        "vectorizer.fit(train_data['text'])  # 텍스트 문서 모음을 토큰 수의 행렬로 변환\n",
        "\n",
        "print(vectorizer.vocabulary_)       # 텍스트 문서에 나타난 어휘의 집합을 출력\n",
        "print(len(vectorizer.vocabulary_))  # 텍스트 문서에 나타난 어휘 집합의 길이를 출력\n",
        "\n",
        "train_vectors = vectorizer.transform(train_data['text'])    # 학습 데이터를 숫자로 변환\n",
        "dev_vectors = vectorizer.transform(dev_data['text'])        # 검증 데이터를 숫자로 변환\n",
        "test_vectors = vectorizer.transform(test_data['text'])      # 테스트 데이터를 숫자로 변환\n",
        "\n",
        "# print(train_vectors)      # transform 된 결과 확인\n",
        "\n",
        "\n",
        "##### 텍스트와 범주형 특성 다루기 (Bag-of-words 방식으로 벡터화 한 것 확인하는 방법 구현)\n",
        "sample_num = -1                            # 확인하고 싶은 샘플 번호\n",
        "sample_origin = train_data[sample_num]    # 확인하고 싶은 샘플의 원래 문장\n",
        "sample_transform = train_vectors[sample_num]    # 확인하고 싶은 샘플의 transform된 결과\n",
        "sample_inverse_transform = vectorizer.inverse_transform(sample_transform) # 확인하고 싶은 샘플의 transform된 결과를 다시 단어의 조합으로 바꾼 결과\n",
        "print(\"Original Input:{}\\nTransformed: {}\\nInv-transformed: {}\".format(sample_origin, sample_transform, sample_inverse_transform))    # 출력"
      ],
      "metadata": {
        "id": "uVsAWEB2Cd2n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15c1e85-3cd0-470d-82d4-982d6b49c9e3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Input:{'label': 0, 'text': \"큰 의미없이 연결'만' 되는 살인들.\"}\n",
            "Transformed:   (0, 90189)\t0.3118234738558217\n",
            "  (0, 69198)\t0.4424379551583432\n",
            "  (0, 61905)\t0.4424379551583432\n",
            "  (0, 45735)\t0.4727867319536863\n",
            "  (0, 25056)\t0.30328995160893885\n",
            "  (0, 91)\t0.4424379551583432\n",
            "Inv-transformed: [array(['큰', '의미없이', '연결', '살인들', '되는', \"'만\"],\n",
            "      dtype='<U338')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 훈련세트에서 훈련하고 평가하기\n",
        "from sklearn.svm import LinearSVC     #Linear kernel SVM을 사용하기 위한 클래스     \n",
        "\n",
        "svm = LinearSVC(random_state = False)     # 모델 정의\n",
        "svm.fit(train_vectors, train_data['label'])     # 모델 학습\n",
        "\n",
        "print(svm.coef_)      # weights (w)\n",
        "print(svm.intercept_)     # bias (b)"
      ],
      "metadata": {
        "id": "u_hMc3yACbYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c9a8e3-dbd7-4f2c-95cd-b88dea46edbd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.31194645 -0.33987567  0.17500192 ... -0.34580584  0.11423295\n",
            "  -0.00327867]]\n",
            "[-0.07857266]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 교차 검증을 사용한 평가\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "all_data = train_data['text']+dev_data['text']+test_data['text']      # all_data = train_data + dev_data + test_data\n",
        "all_label = train_data['label']+dev_data['label']+test_data['label']  # all_label은 train_data, dev_data, test_date의 레이블을 모두 합한 것 \n",
        "all_vectors = vectorizer.transform(all_data)    # all_data를 숫자로 변환\n",
        "scores = cross_val_score(svm, all_vectors, all_label, cv=5)  # 5-cross validation\n",
        "\n",
        "print(\"All scores:\", scores)  # 전체 점수 출력\n",
        "print(\"Average: {:.2f}%\".format(scores.mean()*100)) # 다섯 번의 스코어 평균 출력\n",
        "print(\"Standard deviation: {:.6f}\".format(scores.std()))  # 표준편차 출력\n",
        " "
      ],
      "metadata": {
        "id": "Np-m5f9DCT1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a964db64-f116-4237-cd48-446b87d763bf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All scores: [0.78275  0.786    0.782625 0.78875  0.80025 ]\n",
            "Average: 78.81%\n",
            "Standard deviation: 0.006497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 그리드 탐색\n",
        "# from sklearn.model_selection import GridSearchCV    \n",
        "\n",
        "# param_grid = [{'max_iter':[500, 1000, 5000], 'C': [1, 10, 100]}]        # 학습 max_iter와 C를 변동 하이퍼파라미터로 설정\n",
        "# grid_search = GridSearchCV(svm, param_grid, cv=3)     # 하이퍼파라미터 서치 할 모델 설정, 각 모델별로 5-cross validation 실행\n",
        "# grid_search.fit(train_vectors, train_data['label'])   # transformed train data로 학습\n",
        "\n",
        "# print(grid_search.cv_results_['mean_test_score'])     # 파라미터 서치 결과\n",
        "# print(grid_search.best_params_)   #최고의 모델 파라미터 \n",
        "\n",
        "# #파라미터 서치 결과 출력\n",
        "# for mean_score, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n",
        "#   print(mean_score, params)       "
      ],
      "metadata": {
        "id": "DtH3CLrnCUhy"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 테스트 세트로 시스템 평가하기\n",
        "from sklearn.metrics import accuracy_score    # Accuracy 측정 함수 import\n",
        "\n",
        "final_model = svm #grid_search.best_estimator_     # grid search에 의해 정해진 제일 좋은 하이퍼파라미터\n",
        "\n",
        "pred_results = final_model.predict(test_vectors)    # 최종 모델로 test 데이터 예측\n",
        "accuracy = accuracy_score(test_data['label'], pred_results)   # 정확도 측정\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))   # 정확도 출력 "
      ],
      "metadata": {
        "id": "caRvzXUtCUrv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c88cf95-575d-453d-dae7-2aed7709b8f8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 80.88%\n"
          ]
        }
      ]
    }
  ]
}