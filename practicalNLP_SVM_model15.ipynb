{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "GHnDE3OC6lrl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0c508294-ac90-438c-d9bd-67e61192f993"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!pip install datasets   # Package install\\n\\nfrom datasets import load_dataset   # Huggingface 데이터셋 패키지 import\\ndata = load_dataset(\"sepidmnorozy/Korean_sentiment\")    # 데이터 다운로드\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "##### 데이터 다운로드\n",
        "# 한 번 함\n",
        "'''\n",
        "!pip install datasets   # Package install\n",
        "\n",
        "from datasets import load_dataset   # Huggingface 데이터셋 패키지 import\n",
        "data = load_dataset(\"sepidmnorozy/Korean_sentiment\")    # 데이터 다운로드\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한 번 수행함\n",
        "'''\n",
        "# connect google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Download konlpy\n",
        "%cd ./drive/MyDrive/Colab\\ Notebooks/\n",
        "! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd ./Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab_light_220429.sh\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "6G5nsz6O1ssk",
        "outputId": "5ef7c652-2a5e-44f0-92c1-c78244c1afda"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# connect google drive\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n# Download konlpy\\n%cd ./drive/MyDrive/Colab\\\\ Notebooks/\\n! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\\n%cd ./Mecab-ko-for-Google-Colab\\n!bash install_mecab-ko_on_colab_light_220429.sh\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()\n",
        "\n",
        "sen = \"실용자연어처리 실습 진행중입니다.\"\n",
        "print(mecab.morphs(sen))\n",
        "print(mecab.nouns(sen))\n",
        "print(mecab.pos(sen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFp0OmnZa7yo",
        "outputId": "f6e4e348-b36c-41b6-b3dc-dd26da03307e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['실용', '자연어', '처리', '실습', '진행', '중', '입니다', '.']\n",
            "['실용', '자연어', '처리', '실습', '진행', '중']\n",
            "[('실용', 'NNG'), ('자연어', 'NNG'), ('처리', 'NNG'), ('실습', 'NNG'), ('진행', 'NNG'), ('중', 'NNB'), ('입니다', 'VCP+EF'), ('.', 'SF')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 데이터 구조 훑어보기\n",
        "# print(\"Data type: \", type(data))    # 데이터 타입 확인\n",
        "# print(\"Data structure: \", data)     # 데이터 구조 확인\n",
        "# print(\"Data keys: \", data.keys())   # 데이터 키 확인\n",
        "\n",
        "print(data['train'][0])   # 실제 데이터 확인"
      ],
      "metadata": {
        "id": "8_NM2aMmCjkA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f643a507-7caf-4c39-b70e-39c51b7d2d17"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 1, 'text': '역시 명작 어렸을때 봤을때도 재밌었고 지금 봐도 몇억배 이상으로 재밌어요'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 테스트 세트 만들기\n",
        "train_data = data['train']\n",
        "dev_data = data['validation']\n",
        "test_data = data['test']\n",
        "\n",
        "print(train_data)\n",
        "print(dev_data)\n",
        "print(test_data)\n",
        "\n",
        "train_data = train_data.map(lambda example:{\"label\": example[\"label\"], \"text\": \" \".join(mecab.morphs(example[\"text\"]))})\n",
        "dev_data = dev_data.map(lambda example:{\"label\": example[\"label\"], \"text\": \" \".join(mecab.morphs(example[\"text\"]))})\n",
        "test_data = test_data.map(lambda example:{\"label\": example[\"label\"], \"text\": \" \".join(mecab.morphs(example[\"text\"]))})\n",
        "\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "id": "IqbCh4yMCiEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af347cc1-7835-432f-cfdc-454b0f4c4b6f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/sepidmnorozy___csv/sepidmnorozy--Korean_sentiment-c4fbcaaf8f2ffcfa/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-5a791b0b00b6cf20.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/sepidmnorozy___csv/sepidmnorozy--Korean_sentiment-c4fbcaaf8f2ffcfa/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-e0741f5465b95d00.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/sepidmnorozy___csv/sepidmnorozy--Korean_sentiment-c4fbcaaf8f2ffcfa/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-264d57f600a89812.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['label', 'text'],\n",
            "    num_rows: 36000\n",
            "})\n",
            "Dataset({\n",
            "    features: ['label', 'text'],\n",
            "    num_rows: 1333\n",
            "})\n",
            "Dataset({\n",
            "    features: ['label', 'text'],\n",
            "    num_rows: 2667\n",
            "})\n",
            "{'label': 1, 'text': '역시 명작 어렸 을 때 봤 을 때 도 재밌 었 고 지금 봐도 몇 억 배 이상 으로 재밌 어요'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 텍스트 데이터 특성\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.hist(data['train']['label'], color='red')\n",
        "# plt.show()\n",
        "# plt.hist(data['validation']['label'], color='blue')\n",
        "# plt.show()\n",
        "# plt.hist(data['test']['label'], color='green')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "NSi7J4fvCfRd"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 텍스트와 범주형 특성 다루기 (Bag-of-words 방식으로 벡터화 하는 법 구현)\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer       # CountVectorizer: Bag of words 벡터화 구현을 하기 위한 클래스\n",
        "\n",
        "vectorizer = TfidfVectorizer(strip_accents=\"unicode\", token_pattern = r\"(?u)\\b\\w\\w+\\b|'\\w+\",ngram_range = (1,3))      # 데이터를 벡터화 해주는 모델 \n",
        "vectorizer.fit(train_data['text'])  # 텍스트 문서 모음을 토큰 수의 행렬로 변환\n",
        "\n",
        "print(vectorizer.vocabulary_)       # 텍스트 문서에 나타난 어휘의 집합을 출력\n",
        "print(len(vectorizer.vocabulary_))  # 텍스트 문서에 나타난 어휘 집합의 길이를 출력\n",
        "\n",
        "train_vectors = vectorizer.transform(train_data['text'])    # 학습 데이터를 숫자로 변환\n",
        "dev_vectors = vectorizer.transform(dev_data['text'])        # 검증 데이터를 숫자로 변환\n",
        "test_vectors = vectorizer.transform(test_data['text'])      # 테스트 데이터를 숫자로 변환\n",
        "\n",
        "# print(train_vectors)      # transform 된 결과 확인\n",
        "\n",
        "\n",
        "##### 텍스트와 범주형 특성 다루기 (Bag-of-words 방식으로 벡터화 한 것 확인하는 방법 구현)\n",
        "sample_num = -1                            # 확인하고 싶은 샘플 번호\n",
        "sample_origin = train_data[sample_num]    # 확인하고 싶은 샘플의 원래 문장\n",
        "sample_transform = train_vectors[sample_num]    # 확인하고 싶은 샘플의 transform된 결과\n",
        "sample_inverse_transform = vectorizer.inverse_transform(sample_transform) # 확인하고 싶은 샘플의 transform된 결과를 다시 단어의 조합으로 바꾼 결과\n",
        "print(\"Original Input:{}\\nTransformed: {}\\nInv-transformed: {}\".format(sample_origin, sample_transform, sample_inverse_transform))    # 출력"
      ],
      "metadata": {
        "id": "uVsAWEB2Cd2n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee95dcf-05aa-47fe-c9ef-ae5547b72464"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Input:{'label': 0, 'text': \"큰 의미 없이 연결 ' 만 ' 되 는 살인 들 .\"}\n",
            "Transformed:   (0, 541259)\t0.25012862929894514\n",
            "  (0, 541257)\t0.23407255702011812\n",
            "  (0, 541134)\t0.15667941520269849\n",
            "  (0, 431029)\t0.25012862929894514\n",
            "  (0, 431027)\t0.23407255702011812\n",
            "  (0, 430949)\t0.14876852428112447\n",
            "  (0, 367502)\t0.25012862929894514\n",
            "  (0, 367501)\t0.25012862929894514\n",
            "  (0, 367487)\t0.18899746347924043\n",
            "  (0, 348218)\t0.25012862929894514\n",
            "  (0, 348217)\t0.25012862929894514\n",
            "  (0, 347934)\t0.1319247279551916\n",
            "  (0, 278669)\t0.25012862929894514\n",
            "  (0, 278644)\t0.17699982149606927\n",
            "  (0, 209852)\t0.22890365626002154\n",
            "  (0, 209851)\t0.21801648474129112\n",
            "  (0, 209341)\t0.08332923125439495\n",
            "  (0, 175218)\t0.07229456916362491\n",
            "  (0, 168943)\t0.25012862929894514\n",
            "  (0, 168844)\t0.1214101759863504\n",
            "  (0, 168559)\t0.09479909900232861\n",
            "  (0, 119782)\t0.25012862929894514\n",
            "  (0, 119781)\t0.24073642910696286\n",
            "  (0, 114110)\t0.04927276366374689\n",
            "Inv-transformed: [array(['큰 의미 없이', '큰 의미', '큰', '의미 없이 연결',\n",
            "       '의미 없이', '의미', '연결 만 되', '연결 만', '연결',\n",
            "       '없이 연결 만', '없이 연결', '없이', '살인 들',\n",
            "       '살인', '만 되 는', '만 되', '만', '들', '되 는 살인',\n",
            "       '되 는', '되', '는 살인 들', '는 살인', '는'],\n",
            "      dtype='<U73')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 훈련세트에서 훈련하고 평가하기\n",
        "from sklearn.svm import LinearSVC     #Linear kernel SVM을 사용하기 위한 클래스     \n",
        "\n",
        "svm = LinearSVC(random_state = False)     # 모델 정의\n",
        "svm.fit(train_vectors, train_data['label'])     # 모델 학습\n",
        "\n",
        "print(svm.coef_)      # weights (w)\n",
        "print(svm.intercept_)     # bias (b)"
      ],
      "metadata": {
        "id": "u_hMc3yACbYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8145cae7-087b-4766-acdc-ad8bc33521cc"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.18579303 -0.18579303 -0.18579303 ... -0.02207542 -0.02207542\n",
            "  -0.02207542]]\n",
            "[-0.12368185]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 교차 검증을 사용한 평가\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "all_data = train_data['text']+dev_data['text']+test_data['text']      # all_data = train_data + dev_data + test_data\n",
        "all_label = train_data['label']+dev_data['label']+test_data['label']  # all_label은 train_data, dev_data, test_date의 레이블을 모두 합한 것 \n",
        "all_vectors = vectorizer.transform(all_data)    # all_data를 숫자로 변환\n",
        "scores = cross_val_score(svm, all_vectors, all_label, cv=5)  # 5-cross validation\n",
        "\n",
        "print(\"All scores:\", scores)  # 전체 점수 출력\n",
        "print(\"Average: {:.2f}%\".format(scores.mean()*100)) # 다섯 번의 스코어 평균 출력\n",
        "print(\"Standard deviation: {:.6f}\".format(scores.std()))  # 표준편차 출력\n",
        " "
      ],
      "metadata": {
        "id": "Np-m5f9DCT1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b24a687-2170-47dc-b976-b50efa4dc572"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All scores: [0.846625 0.852375 0.850625 0.848125 0.8555  ]\n",
            "Average: 85.06%\n",
            "Standard deviation: 0.003133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 그리드 탐색\n",
        "# from sklearn.model_selection import GridSearchCV    \n",
        "\n",
        "# param_grid = [{'max_iter':[500, 1000, 5000], 'C': [1, 10, 100]}]        # 학습 max_iter와 C를 변동 하이퍼파라미터로 설정\n",
        "# grid_search = GridSearchCV(svm, param_grid, cv=3)     # 하이퍼파라미터 서치 할 모델 설정, 각 모델별로 5-cross validation 실행\n",
        "# grid_search.fit(train_vectors, train_data['label'])   # transformed train data로 학습\n",
        "\n",
        "# print(grid_search.cv_results_['mean_test_score'])     # 파라미터 서치 결과\n",
        "# print(grid_search.best_params_)   #최고의 모델 파라미터 \n",
        "\n",
        "# #파라미터 서치 결과 출력\n",
        "# for mean_score, params in zip(grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['params']):\n",
        "#   print(mean_score, params)       "
      ],
      "metadata": {
        "id": "DtH3CLrnCUhy"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### 테스트 세트로 시스템 평가하기\n",
        "from sklearn.metrics import accuracy_score    # Accuracy 측정 함수 import\n",
        "\n",
        "final_model = svm #grid_search.best_estimator_     # grid search에 의해 정해진 제일 좋은 하이퍼파라미터\n",
        "\n",
        "pred_results = final_model.predict(test_vectors)    # 최종 모델로 test 데이터 예측\n",
        "accuracy = accuracy_score(test_data['label'], pred_results)   # 정확도 측정\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))   # 정확도 출력 "
      ],
      "metadata": {
        "id": "caRvzXUtCUrv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c85c99c-1533-4889-c95a-beb82e29adf9"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 86.20%\n"
          ]
        }
      ]
    }
  ]
}